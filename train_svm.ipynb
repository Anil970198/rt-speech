{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Real-Time Speech Assessment - SVM Training\n",
                "\n",
                "This notebook extracts audio features (MFCC, Pitch, RMS) from the RAVDESS dataset and trains a Support Vector Machine (SVM) classifier for stress detection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install librosa scikit-learn tqdm numpy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import numpy as np\n",
                "import pickle\n",
                "import librosa\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.pipeline import make_pipeline\n",
                "from sklearn.metrics import classification_report\n",
                "from tqdm.notebook import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "# If running on Kaggle, dataset is usually at /kaggle/input/ravdess-emotional-speech-audio\n",
                "# If local, usually 'data'\n",
                "DATA_DIRS = [\n",
                "    \"/kaggle/input/ravdess-emotional-speech-audio\",\n",
                "    \"../input/ravdess-emotional-speech-audio\",\n",
                "    \"data\",\n",
                "    \"../data\"\n",
                "]\n",
                "MODEL_FILENAME = \"svm_stress.pkl\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Extraction Logic (Same as src/features.py)\n",
                "def extract_features(y, sr=16000):\n",
                "    # 1. RMS Energy (Loudness)\n",
                "    rms = np.sqrt(np.mean(y**2))\n",
                "    \n",
                "    # 2. Zero Crossing Rate (Roughness)\n",
                "    zcr = ((y[:-1] * y[1:]) < 0).sum() / len(y)\n",
                "    \n",
                "    # 3. MFCCs (Timbre)\n",
                "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
                "    mfcc_mean = np.mean(mfccs, axis=1)\n",
                "    \n",
                "    # 4. Pitch (F0) - Simple Heuristic via ZCR/Pyin would be too slow, use simple approximation\n",
                "    # For training speed, we can skip complex pitch tracking or use a fast one.\n",
                "    # We'll use a placeholder for speed in bulk processing or simple peak.\n",
                "    f0 = 0.0\n",
                "    \n",
                "    return mfcc_mean.tolist() + [float(rms), float(zcr), float(f0)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data():\n",
                "    valid_files = []\n",
                "    for d in DATA_DIRS:\n",
                "        if os.path.exists(d):\n",
                "            print(f\"Scanning {d}...\")\n",
                "            files = glob.glob(os.path.join(d, \"**/*.wav\"), recursive=True)\n",
                "            files += glob.glob(os.path.join(d, \"**/*.mp4\"), recursive=True)\n",
                "            valid_files.extend(files)\n",
                "    \n",
                "    if not valid_files:\n",
                "        print(\"No files found! Check DATA_DIRS.\")\n",
                "        return None, None\n",
                "        \n",
                "    print(f\"Found {len(valid_files)} files. Processing...\")\n",
                "    X, y = [], []\n",
                "    \n",
                "    for f in tqdm(valid_files):\n",
                "        try:\n",
                "            basename = os.path.basename(f)\n",
                "            parts = basename.split(\"-\")\n",
                "            if len(parts) < 3: continue\n",
                "            emotion = int(parts[2])\n",
                "            \n",
                "            # 01=Neutral, 02=Calm, 03=Happy -> CALM (0)\n",
                "            # 04=Sad, 05=Angry, 06=Fear, 07=Disgust -> STRESS (1)\n",
                "            if emotion in [1, 2, 3]: label = 0\n",
                "            elif emotion in [4, 5, 6, 7]: label = 1\n",
                "            else: continue\n",
                "            \n",
                "            # Load Audio\n",
                "            y_audio, sr = librosa.load(f, sr=16000)\n",
                "            feats = extract_features(y_audio, sr)\n",
                "            X.append(feats)\n",
                "            y.append(label)\n",
                "        except Exception as e:\n",
                "            pass\n",
                "            \n",
                "    return np.array(X), np.array(y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X, y = load_data()\n",
                "if X is not None:\n",
                "    print(f\"Data Shape: {X.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if X is not None:\n",
                "    # Split\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "    # Train SVM\n",
                "    print(\"Training SVM...\")\n",
                "    model = make_pipeline(StandardScaler(), SVC(probability=True, kernel='rbf'))\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # Evaluate\n",
                "    print(\"Evaluation:\")\n",
                "    print(model.score(X_test, y_test))\n",
                "    \n",
                "    # Save\n",
                "    with open(MODEL_FILENAME, 'wb') as f:\n",
                "        pickle.dump({'model': model['svc'], 'scaler': model['standardscaler']}, f)\n",
                "    print(f\"Model saved to {MODEL_FILENAME}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}